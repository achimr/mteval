# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/09_ter.ipynb.

# %% auto 0
__all__ = ['measure_ter', 'measure_record_ter']

# %% ../nbs/09_ter.ipynb 6
from sacrebleu.metrics import TER
def measure_ter(hypothesis_lines,reference_lines,normalized=False,no_punct=False,asian_support=False,case_sensitive=False):
    """Measuring TER on set of hypotheses and references
    
    Parameters
    ----------
    hypothesis_lines : List 
        Array of hypotheses.
    reference_lines : List
        Array of references.
    normalized : bool, default=False
        If `True`, applies basic tokenization to sentences.
    no_punct : bool, default=False
        If `True`, removes punctuations from sentences.
    asian_support : bool, default=False
        If `True`, adds support for Asian character processing.
    case_sensitive : bool, default=False
        If `True`, does not lowercase sentences.
    
    Returns
    -------
    Tuple
        Array of arrays containing TER score, number of edits and reference length and sacreBLEU TER score in JSON format.
    """
    # Calculate corpus level score
    ter = TER(normalized=normalized,no_punct=no_punct,asian_support=asian_support,case_sensitive=case_sensitive)
    corpus_score = ter.corpus_score(hypothesis_lines,[reference_lines])
    sig = ter.get_signature().format(short=False)
    score_json = corpus_score.format(width=2,score_only=False,signature=sig,is_json=True)
    
    # Calculate segment level scores
    seg_scores = []
    for hypothesis, reference in zip(hypothesis_lines,reference_lines):
        seg_score = ter.sentence_score(hypothesis,[reference])
        seg_scores.append([seg_score.score,seg_score.num_edits,seg_score.ref_length])
    return seg_scores, score_json

# %% ../nbs/09_ter.ipynb 7
import csv
import json
import sys
import os
from pathlib import Path
def measure_record_ter(hypothesis_lines,reference_lines,sourcelang,targetlang,test_set_name,test_date,mtengine,score_pathname,score_fname,domain='',normalized=False,no_punct=False,asian_support=False,case_sensitive=False):
    """Score hypothesis with TER score and record it to a specified metrics file
    
    Parameters
    ----------
    hypothesis_lines : List 
        Array of hypotheses.
    reference_lines : List
        Array of references.
    sourcelang : str
        Source language identifier.
    targetlang : str
        Target language identifier.
    test_set_name : str
        Name of test set.
    test_date : str
        Date of test as ISO-8601 formatted string.
    mtengine : str
        Name of the tested MT engine.
    score_pathname : str
        Path for results CSV file.
    score_fname : str
        File name for results CSV file.
    domain : str, default=''
        Domain string if applicable.
    normalized : bool, default=False
        If `True`, applies basic tokenization to sentences.
    no_punct : bool, default=False
        If `True`, removes punctuations from sentences.
    asian_support : bool, default=False
        If `True`, adds support for Asian character processing.
    case_sensitive : bool, default=False
        If `True`, does not lowercase sentences.
    """
    seg_scores, score_json = measure_ter(hypothesis_lines,reference_lines,normalized,no_punct,asian_support,case_sensitive)

    score_dict = json.loads(score_json)
    metric_record = score_dict
    metric_record["date"] = test_date
    metric_record["source_langid"] = sourcelang
    metric_record["target_langid"] = targetlang
    metric_record["test_set"] = test_set_name
    metric_record["engine"] = mtengine
    metric_record["domain"] = domain
    score_path = Path(score_pathname,score_fname)
    with open(score_path,"a",newline="") as score_file:
        field_names = metric_record.keys()
        writer = csv.DictWriter(score_file, fieldnames=field_names)
        if score_file.tell() == 0:
            writer.writeheader()
        writer.writerow(metric_record)
    
    # Write segment level TER scores to plain text file
    output_path = score_pathname+"/"+sourcelang+"_"+targetlang+"/"+test_date+"/"+test_set_name
    os.makedirs(output_path,exist_ok=True)
    seg_score_fname = ""
    if domain:
        seg_score_fname = "ter_"+mtengine+"."+domain+"."+sourcelang+"-"+targetlang
    else:
        seg_score_fname = "ter_"+mtengine+"."+sourcelang+"-"+targetlang
    seg_score_path = Path(output_path,seg_score_fname)
    with open(seg_score_path,"w",newline="") as seg_score_fh:
        writer = csv.writer(seg_score_fh)
        for seg_score in seg_scores:
            writer.writerow(seg_score)
    
